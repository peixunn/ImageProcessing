{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4519ca4e-9baa-4bdc-8671-66416b88efc6",
   "metadata": {},
   "source": [
    "# Template Matching OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c4245c-29b2-4560-9f97-49454c38c4e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded template: 0\n",
      "Loaded template: 1\n",
      "Loaded template: 2\n",
      "Loaded template: 3\n",
      "Loaded template: 4\n",
      "Loaded template: 5\n",
      "Loaded template: 6\n",
      "Loaded template: 7\n",
      "Loaded template: 8\n",
      "Loaded template: 9\n",
      "Loaded template: A\n",
      "Loaded template: B\n",
      "Loaded template: C\n",
      "Loaded template: D\n",
      "Loaded template: E\n",
      "Loaded template: F\n",
      "Loaded template: G\n",
      "Loaded template: H\n",
      "Loaded template: I\n",
      "Loaded template: J\n",
      "Loaded template: K\n",
      "Loaded template: L\n",
      "Loaded template: M\n",
      "Loaded template: N\n",
      "Loaded template: O\n",
      "Loaded template: P\n",
      "Loaded template: Q\n",
      "Loaded template: R\n",
      "Loaded template: S\n",
      "Loaded template: T\n",
      "Loaded template: U\n",
      "Loaded template: V\n",
      "Loaded template: W\n",
      "Loaded template: X\n",
      "Loaded template: Y\n",
      "Loaded template: Z\n",
      "Loaded 36 templates\n",
      "Character templates: 36\n",
      "Field templates: 0\n",
      "No field templates found. Using manual region definitions.\n",
      "Student Name: ?????W???\n",
      "Student ID: ??W?????\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def load_image(image_path):\n",
    "    \"\"\"Load the image and convert to grayscale\"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Could not load image from {image_path}\")\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return gray, img\n",
    "\n",
    "def load_templates(template_dir):\n",
    "    \"\"\"Load all template images from a directory\"\"\"\n",
    "    templates = {}\n",
    "    \n",
    "    if not os.path.exists(template_dir):\n",
    "        raise ValueError(f\"Template directory {template_dir} does not exist!\")\n",
    "    \n",
    "    template_files = [f for f in os.listdir(template_dir) if f.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]\n",
    "    \n",
    "    if not template_files:\n",
    "        raise ValueError(f\"No template images found in {template_dir}\")\n",
    "    \n",
    "    for file in template_files:\n",
    "        # Extract character name from filename (assuming format like \"A.png\", \"B.png\", etc.)\n",
    "        char_name = os.path.splitext(file)[0]\n",
    "        template_path = os.path.join(template_dir, file)\n",
    "        template = cv2.imread(template_path, 0)  # Read as grayscale\n",
    "        \n",
    "        if template is not None:\n",
    "            templates[char_name] = template\n",
    "            print(f\"Loaded template: {char_name}\")\n",
    "        else:\n",
    "            print(f\"Warning: Could not load template {template_path}\")\n",
    "    \n",
    "    return templates\n",
    "\n",
    "def match_character(roi, templates, threshold=0.7):\n",
    "    \"\"\"Match a character region against all templates\"\"\"\n",
    "    best_match = None\n",
    "    best_score = -1\n",
    "    \n",
    "    for char, template in templates.items():\n",
    "        # Resize template to match ROI size if needed\n",
    "        if roi.shape != template.shape:\n",
    "            resized_template = cv2.resize(template, (roi.shape[1], roi.shape[0]))\n",
    "        else:\n",
    "            resized_template = template\n",
    "            \n",
    "        result = cv2.matchTemplate(roi, resized_template, cv2.TM_CCOEFF_NORMED)\n",
    "        _, max_val, _, _ = cv2.minMaxLoc(result)\n",
    "        \n",
    "        if max_val > best_score and max_val > threshold:\n",
    "            best_score = max_val\n",
    "            best_match = char\n",
    "    \n",
    "    return best_match if best_score > threshold else \"?\"\n",
    "\n",
    "def extract_text_with_templates(image, x, y, w, h, templates):\n",
    "    \"\"\"Extract text from a region using template matching\"\"\"\n",
    "    roi = image[y:y+h, x:x+w]\n",
    "    \n",
    "    # Preprocess the ROI\n",
    "    _, binary = cv2.threshold(roi, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    contours = sorted(contours, key=lambda c: cv2.boundingRect(c)[0])\n",
    "    \n",
    "    text = \"\"\n",
    "    for contour in contours:\n",
    "        x_c, y_c, w_c, h_c = cv2.boundingRect(contour)\n",
    "        \n",
    "        if w_c < 5 or h_c < 10:\n",
    "            continue\n",
    "            \n",
    "        char_roi = roi[y_c:y_c+h_c, x_c:x_c+w_c]\n",
    "        \n",
    "        char = match_character(char_roi, templates)\n",
    "        text += char\n",
    "    \n",
    "    return text\n",
    "\n",
    "def find_field_locations(image, field_templates):\n",
    "    \"\"\"Find locations of specific fields using their label templates\"\"\"\n",
    "    field_regions = {}\n",
    "    \n",
    "    for field_name, template in field_templates.items():\n",
    "        # Perform template matching\n",
    "        result = cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED)\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "        \n",
    "        if max_val > 0.6:  # Good match threshold\n",
    "            # Get template dimensions\n",
    "            h, w = template.shape\n",
    "            \n",
    "            # Estimate position of the field value (assuming it's to the right of the label)\n",
    "            field_x = max_loc[0] + w + 10  # 10 pixels padding\n",
    "            field_y = max_loc[1]\n",
    "            field_width = 200  # Estimated width of the field value\n",
    "            field_height = h\n",
    "            \n",
    "            field_regions[field_name] = (field_x, field_y, field_width, field_height)\n",
    "            \n",
    "            # For debugging: visualize the found template\n",
    "            debug_img = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "            cv2.rectangle(debug_img, max_loc, (max_loc[0] + w, max_loc[1] + h), (0, 255, 0), 2)\n",
    "            cv2.putText(debug_img, field_name, (max_loc[0], max_loc[1]-10), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            cv2.imshow(f\"Found {field_name} template\", debug_img)\n",
    "            cv2.waitKey(0)\n",
    "    \n",
    "    return field_regions\n",
    "\n",
    "def main():\n",
    "    # Path to your image and templates\n",
    "    image_path = \"id\"\n",
    "    template_dir = \"templates\"  # Directory with all templates\n",
    "    \n",
    "    # Load image\n",
    "    gray, original = load_image(image_path)\n",
    "    \n",
    "    # Load all templates from the directory\n",
    "    try:\n",
    "        templates = load_templates(template_dir)\n",
    "        print(f\"Loaded {len(templates)} templates\")\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        return\n",
    "    \n",
    "    # Separate character templates from field templates\n",
    "    char_templates = {}\n",
    "    field_templates = {}\n",
    "    \n",
    "    for name, template in templates.items():\n",
    "        # Assuming field templates have longer names (like \"STUDENT\", \"ID\")\n",
    "        # and character templates are single characters\n",
    "        if len(name) == 1:\n",
    "            char_templates[name] = template\n",
    "        else:\n",
    "            field_templates[name] = template\n",
    "    \n",
    "    print(f\"Character templates: {len(char_templates)}\")\n",
    "    print(f\"Field templates: {len(field_templates)}\")\n",
    "    \n",
    "    # Find field locations if we have field templates\n",
    "    if field_templates:\n",
    "        field_regions = find_field_locations(gray, field_templates)\n",
    "        \n",
    "        # Extract text from each field\n",
    "        for field_name, region in field_regions.items():\n",
    "            text = extract_text_with_templates(gray, *region, char_templates)\n",
    "            print(f\"{field_name}: {text}\")\n",
    "    else:\n",
    "        # Manual region definitions (fallback if no field templates)\n",
    "        print(\"No field templates found. Using manual region definitions.\")\n",
    "        \n",
    "        # Define regions manually (you'll need to adjust these)\n",
    "        student_region = (150, 100, 280, 40)  # (x, y, w, h)\n",
    "        id_region = (150, 135, 280, 40)\n",
    "        \n",
    "        # Extract text from regions\n",
    "        student_name = extract_text_with_templates(gray, *student_region, char_templates)\n",
    "        student_id = extract_text_with_templates(gray, *id_region, char_templates)\n",
    "        \n",
    "        print(f\"Student Name: {student_name}\")\n",
    "        print(f\"Student ID: {student_id}\")\n",
    "        \n",
    "        # Visualize the regions (for debugging)\n",
    "        debug_img = original.copy()\n",
    "        cv2.rectangle(debug_img, \n",
    "                     (student_region[0], student_region[1]), \n",
    "                     (student_region[0] + student_region[2], student_region[1] + student_region[3]), \n",
    "                     (0, 255, 0), 2)\n",
    "        cv2.rectangle(debug_img, \n",
    "                     (id_region[0], id_region[1]), \n",
    "                     (id_region[0] + id_region[2], id_region[1] + id_region[3]), \n",
    "                     (255, 0, 0), 2)\n",
    "        \n",
    "        # Add labels to original fields\n",
    "        cv2.putText(debug_img, \"Name\", (student_region[0], student_region[1]-10), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        cv2.putText(debug_img, \"ID\", (id_region[0], id_region[1]-10), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "        # ✅ Display name and ID on top-left\n",
    "        cv2.putText(debug_img, f\"Name: {student_name}\", (10, 30), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "        cv2.putText(debug_img, f\"ID: {student_id}\", (10, 60), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
    "\n",
    "        # Show image\n",
    "        cv2.imshow(\"Template Matching OCR Result\", debug_img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5a36bb-de71-4f3b-abae-d5e01d76d51a",
   "metadata": {},
   "source": [
    "# Tesseract OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86853911-aedd-411e-9768-61b068c5b3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import pytesseract\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "img = cv.imread(\"id\")\n",
    "if img is None:\n",
    "    raise ValueError(\"无法读取 id.png，请确认路径正确\")\n",
    "\n",
    "student_region = (150, 100, 280, 40)  # (x, y, w, h)\n",
    "id_region = (150, 135, 280, 40)\n",
    "\n",
    "def preprocess_and_ocr(img, region):\n",
    "    x, y, w, h = region\n",
    "    cropped = img[y:y+h, x:x+w]\n",
    "    gray = cv.cvtColor(cropped, cv.COLOR_BGR2GRAY)\n",
    "    _, binary = cv.threshold(gray, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "    text = pytesseract.image_to_string(binary, lang='chi_sim+eng', config='--psm 7').strip()\n",
    "    return text\n",
    "\n",
    "student_name = preprocess_and_ocr(img, student_region)\n",
    "student_id = preprocess_and_ocr(img, id_region)\n",
    "\n",
    "cv.rectangle(img, (student_region[0], student_region[1]), (student_region[0]+student_region[2], student_region[1]+student_region[3]), (0,255,0), 2)\n",
    "cv.rectangle(img, (id_region[0], id_region[1]), (id_region[0]+id_region[2], id_region[1]+id_region[3]), (255,0,0), 2)\n",
    "\n",
    "cv.putText(img, f\"Name: {student_name}\", (10, 30), cv.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,0), 2)\n",
    "cv.putText(img, f\"ID: {student_id}\", (10, 60), cv.FONT_HERSHEY_SIMPLEX, 0.8, (255,0,0), 2)\n",
    "\n",
    "cv.imshow(\"Tesseract OCR Result\", img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
